\documentclass[11pt]{article}

\usepackage{listings}
\usepackage{hyperref}
\usepackage{fullpage}

\begin{document}

\title{Notes: Prolog, ILP, ALP, TAL, ASP and examples}

\author{Vitalii Protsenko}

\date{}

\maketitle

\section{Prolog}

\subsection{Basics}

\begin{itemize}
  \item Based on rules, ie \texttt{dog(a).} means the fact \texttt{'a is a dog'}.
  \item Rules can be derived from other rules by implications \texttt{ :- } or, more naturally,  $\leftarrow$. For example we can write \texttt{animal(A) :- dog(A).}, which would mean \texttt{A is an animal $\leftarrow$ A is a dog}.
  \item Worth mentioning that A is a variable, meaning that $\forall A$ : $A$ is a dog $\rightarrow$ $A$ is an animal.
  \item We can write a more complex rules by using $\wedge$, which in Prolog syntax is just a comma. For example: \texttt{sister(X, Y) :- parent(Z, X), parent(Z, Y), female(X).} in first-order logic will look like $\forall x \forall y \forall z$ : sister(X,Y) $\leftarrow$ parent(Z, X) $\wedge$ parent(Z, Y) $\wedge$ female(X)
\end{itemize}

\subsection{Recursion}
We may want to define some more complex family relations, like \texttt{grandparent(X,Z) :- parent(X, Y), parent(Y, Z).}, but what about grand-grand parent etc \ldots ? Luckily, Prolog allows us to use recursive definitions; let us define \texttt{predecessor}:
\begin{lstlisting}
predecessor(X, Z) :-
  parent(X, Z).
predecessor(X, Z) :-
  parent(X, Y),
  predecessor(Y, Z).
\end{lstlisting}
Notice that the base case is necessary if X is a direct parent of Z.\\Also, we need to be careful of infinite looping, as the rule \texttt{r(A) :- r(A).}, for example, is quite dangerous.

\subsection{Variables}
As seen before, variables always start with an upper-case letter or an underscore eg \texttt{\_x} is a valid Prolog variable; furthermore, Prolog renames all the upper-case user defined variables into the underscore-type one automatically for us while executing the code.\\
We can also use anonymous variable - underscore, and the value of that variable is not output when Prolog answeres the question:
\begin{lstlisting}
?- parent(X, _).
\end{lstlisting}
will ask whether X is a parent of anybody.

\subsection{Structures}
We can define some structures like \texttt{date(Day, Month, Year).}, as it is easy to make queries on that format, eg:
\begin{lstlisting}
date(13, july, 2013).
?- date(Day, july, 2013).
   Day = 13.
\end{lstlisting}

\subsection{Lists}
\emph{List} is a simple data structure, a sequence of any number of items. In Prolog a typical list can be written like that: 
\begin{lstlisting}
[1, 2, dog, sun]
\end{lstlisting}
and, of course, this is just a syntactical sugar for 
\begin{lstlisting}
.(1, .(2, .(dog, .(sun, []))))
\end{lstlisting} 
It is also possible to have nested lists
\begin{lstlisting}
[I, [am, [nested]]]
\end{lstlisting}
In addition, there is a very useful feature that allows us to split list into \emph{Head and Tail}:
\begin{lstlisting}
List = [1, 2, 3]
Tail = [2, 3]
-> List = .(1,Tail)
\end{lstlisting}
or in bracket notation:
\begin{lstlisting}
List = [1|Tail]
\end{lstlisting}
In Prolog lists are handled as a binary trees, thus it accepts lists in different formats:
\begin{lstlisting}
[1, 2, ...]
[Head|Tail]
[1, 2,...|Other]
\end{lstlisting}

\subsection{Operators}
We can define new operators by inserting certain kinds of clauses, called \emph{directives}. For example, we may want to define the operator \texttt{has} for our rule \texttt{Alex has info.},
this can be done by defining the directive:
\begin{lstlisting}
:- op(300, xfx, has).
\end{lstlisting}
where 300 is the precedence and \texttt{xfx} means the infix operator.\\\\
There are three groups of operators:
\begin{enumerate}
\item infix operators: \texttt{xfx, xfy, yfx}
\item prefix operators: \texttt{fx. fy}
\item postfix operators: \texttt{xf, yf}
\end{enumerate}
where \texttt{f} represents the operator and \texttt{x} and \texttt{y} represent arguments.

\subsection{Backtracking and Cut}
\textbf{Backtracking}\\
We can also have backtracking in rules. For example consider the following program:
\begin{lstlisting}
hold_party(X):-
  birthday(X),
  happy(X).
  
birthday(tom).
birthday(fred).
birthday(helen).

happy(mary).
happy(jane).
happy(helen).
\end{lstlisting}
If we now pose the query:
\begin{lstlisting}
?- hold_party(Who).
\end{lstlisting}
In order to solve the above, Prolog first attempts to find a clause of birthday, 
it being the first subgoal of birthday. This binds X to tom.
 We then attempt the goal \texttt{happy(tom)}. This will fail, since it doesn't match t
 he above database. As a result, Prolog backtracks. This means that Prolog goes
  back to its last choice point and sees if there is an alternative solution. 
  In this case, this means going back and attempting to find another clause of birthday. 
  This time we can use clause two, binding X to fred. This then causes 
  us to try the goal \texttt{happy(fred)}. Again this will fail to match our database.
   As a result, we backtrack again. This time we find clause three of birthday,
    and bind X to helen, and attempt the goal \texttt{happy(helen)}. This goal matches 
    against clause 3 of our happy database. As a result, \texttt{hold\_party} will succeed 
    with \texttt{X=helen.}\\\\
\textbf{Cut}\\
Prolog automatically backtracks for us if this is necessary for satisfying the goal, although we may want to control that by preventing backtracking. We can do this by using \texttt{cut} function, or just \texttt{!}.\\\\
For me, the easiest way of understanding this concept is to use an example. Lets imagine that we have a relation \texttt{member(X, L).} which will check whether X is in list L. This program would look like:
\begin{lstlisting}
member(X, [X | Xs]).
member(X, [Y | Ys]) :-
  member(X, Ys).
\end{lstlisting}
But such an implementation is not ideal, because if X occurs several times then any occurrence can be found. We can change \texttt{member} in a way such that the program will stop after the first occurrence of X:
\begin{lstlisting}
member(X, [X | Xs]) :- !.
member(X, [Y | Ys]) :-
  member(X, Ys).
\end{lstlisting}
This program will generate just one solution, eg:
\begin{lstlisting}
?- member(X, [1, 2, 3]).
  X = 1;
  no
\end{lstlisting}
I found the cut being very useful even for a simple rule like \texttt{not}:
\begin{lstlisting}
not(A) :-
  A, !, fail ; true.
\end{lstlisting}


\subsection{Practice}
Using the basic concepts introduced so far let us write a few basic rules:
\begin{lstlisting}
factorial:
fac(N) :- fac(N, 1).
fac(0, P) :- write(P).
fac(N, P) :- N>0, M is N-1, K is N * P, fac(M, K).

list concatenation:
conc([ ], L, L).
conc([ X | L1 ], L2, [ X | L3 ]) :- 
  conc(L1, L2, L3).

calculation the length of the list:
length(L, N) :-
  length(L, 0, N).
length([], N, N).
length([_ | L], N0, N) :-
  N1 is N0+1,
  length(L, N1, N).

etc...
\end{lstlisting}
A lot more examples such as sudoku solver etc can be found on my github page \url{https://github.com/vitpro/ilp_alp_tal/tree/master/src}


\section{Answer Set Programming}

\subsection{Basics and tools used}
\emph{Answer Set Programming} or \emph{ASP} is a form of declarative programming based on stable model semantics of logic programming.  
The following tools were suggested:

\begin{description}
  \item[gringo] \hfill \\
  Grounder capable of translating logic programs provided by the programmer into equivalent ground programs
  \item[clasp] \hfill \\
  Solver for the grounded programs computed by gringo, producing answer sets
  \item[clingo] \hfill \\
  Bounds \texttt{gringo} and \texttt{clasp}, taking a logic program as an input and producing answer sets an an output. 
\end{description}

\subsection{Comparison: Clingo and Prolog}
As in Prolog, syntax is very similar, as they both represent logic programming.
Typical ASP program is a collection of:
\begin{itemize}
\item \textbf{Facts:} $A_0.$
\item \textbf{Rules:} $A_0 $ :- $ L_0,...,L_n.$
\item \textbf{Integrity Constants:} $ $ :- $ L_0,...,L_n.$
\end{itemize}
Where $A_0$ is an \emph{atom}, and any of $L_i$'s are \emph{literals}.\\
The set $\{L_0,...,L_n\}$ is called the \emph{body} of the rule. Facts have an empty body.\\

\textbf{Negation}\\
In ASP the predicate \texttt{not} can also be represented as \texttt{'-'}. Semantically, $-A$ will just be a new atom, where $A \cup -A \models {\O}$.\\

\textbf{Disjunction}\\
Additionally, there is a disjunction connective \texttt{'|'} in ASP. Disjunction is true if at least one of its atoms is true. For example: \texttt{a | b.} will produce two answer sets $\{a\}$ and $\{b\}$. I understand it as \emph{or}.\\

\textbf{Assignments}\\
Differently to Prolog, where assignments are implemented as an infix operator \texttt{is}, ASP provides us different notation of \texttt{:-}. There is also a comparison predicate \texttt{==}.\\ Worth mentioning that assignments \emph{bind} variables, which excludes the cases containing looped assignments. For example, the code \texttt{r(A) :- A = B, B = A.} is rejected by \texttt{gringo}.\\

\textbf{Intervals}\\
There is a very neat approach to interval representations. This is easy to understand from an example: \texttt{number(1..9).} will mean all numbers from 1 to 9 inclusive.\\Another handy feature is \emph{pooling}, which means that instead of writing \texttt{rule(a). rule(b). rule(c).} we can write \texttt{rule(a;b;c).}\\

\textbf{Conditions}\\
Conditions can be represented by \texttt{':'} symbol. Lets consider the following program:
\begin{lstlisting}
day(mon). day(tue). day(wed). day(thu). day(fri). day(sat). day(sun).
weekend(sat). weekend(sun).
that(X) : day(X) :- doSomething.
weekdays :- day(X) : day(X) : not weekend(X).
\end{lstlisting}
In my understanding, \texttt{':'} is somehow similar to 
\texttt{foreach} statements from most imperative programming languages. 
Lets consider the line \texttt{that(X) : day(X) :- doSomething.} 
Essentially, it just means 
\texttt{that(mon) | that(tue) | that(wed) | that(thu) | that(fri) | that(sat) | that(sun) :- doSomething.}\\
More interesting example is \texttt{weekdays :- day(X) : day(X) : not weekend(X).} allowing us to use the same atom, \texttt{day(X)}, twice. Gringo simplifies out code to this:  \texttt{weekdays :- day(mon), day(tue), day(wed), day(thu), day(fri).} which is probably easier to read and understand.\\

\textbf{Aggregates}\\
ASP allows us to do operation on sets of literals that evaluates to some values. The aggregate has the following format: $l$\texttt{ op }$[L_0 = \omega_0 , ... , L_n = \omega_n] \upsilon$, where $l$ and $\upsilon$ are lower and upper bounds respectively, operator \texttt{op} and a set of weighted literals $L_i$. Of course, the use of $l$ and $\upsilon$ is entirely optional.\\
Here are a few examples using such aggregates:\\
\begin{lstlisting}
1 #count {a,a, not b,not b} 1.
2 #sum [a, not b, c=2] 3
etc...
\end{lstlisting}
Note that \texttt{\#count} requires curly brackets as there must be no weighted literals within an aggregate.\\

\textbf{Meta Statements}\\
In order to make the language more flexible there are meta statements introduced in ASP. There is a short list of them:
\begin{description}
  \item[Comments] \hfill \\
  \begin{lstlisting}
rule(1). % here is a comment
%*
commented_rule
*%
  \end{lstlisting}
  \item[Hiding predicates] \hfill \\
  \texttt{\#hide} is useful to hide information you don't want to display
  \begin{lstlisting}
#hide.               % Suppress all atoms in output
#hide p/3.           % Suppress all atoms of predicate p/3 in output
#hide p(X,Y) : q(X). % Supress p/3 if the condition holds
  \end{lstlisting}
  In order to selectively include the atoms of a certain predicate in the output, we can use the \texttt{\#show} declarative.
  \begin{lstlisting}
#show p/3.           % Include all atoms of predicate p/3 in output
#show(X,Y) : q(X).   % Include p/3 if the condition holds
  \end{lstlisting}
  \item[Use of constants] \hfill \\
  Constants are just place holders for concrete values provided by a user. 
  By using the \texttt{\#const} declarative we can define a default value to be
inserted for a constant:
   \begin{lstlisting}
#const a = 15.
#const g = f(a,b).
  \end{lstlisting}
  \item[Lua code snippets] \hfill \\
  Ability to include scripting language inside logic programs can be very useful, 
  if used correctly (accessing the database, for example). 
  It is done by writing \texttt{\#begin\_lua} and \texttt{\#end\_lua.}, 
  and having your Lua code in between the tags. We can refer to our Lua snippet via \texttt{@} operator:
     \begin{lstlisting}
#begin_lua
function gcd(a, b)
  if a == 0 then return b
  else return gcd(b % a, a)
  end
end
#end_lua.

gcd(X,Y,@gcd(X,Y)) :- f(X,Y).
  \end{lstlisting}
\end{description}


\section{Inductive Logic Programming}

\subsection{Basic Idea}

\emph{Inductive Logic Programming}, from here on referred to as \emph{ILP}, is an approach to machine learning.\\
In ILP the definitions of relations are deduced from examples, which means that a program is automatically constructed from a set of examples.\\
It is a framework that allows a programmer to define examples and some background knowledge instead of writing the programs directly.\\\\
Typical ILP problem formulation:\\Given:
\begin{enumerate}
\item A set of positive \emph{$E_+$} and negative \emph{$E_-$} examples
\item Background knowledge \emph{B}, represented as a set of logic formulas, such that the examples \emph{$E_+$} cannot be derived from \emph{B}
\end{enumerate}
Find:\\
A hypothesis \emph{H}, represented as a set of logic formulas, such that:
\begin{enumerate}
\item All examples in \emph{$E_+$} can be derived from \emph{B} and \emph{H}
\item No examples in \emph{$E_-$} can be derived from \emph{B} and \emph{H}
\end{enumerate}
More precisely:
\\
An ILP task is defined as \emph{$\langle E, B, L_H\rangle$} where \emph{E} is a set of examples, \emph{B} is a background knowledge and \emph{$L_H$} set of logic theories, called language bias.\\
\emph{H} is a hypothesis for a given ILP task \emph{$\langle E, B, L_H\rangle$ iff H $\in L_H$, and B $\cup$ H $\models$ E}. 

\subsection{HYPER}
\paragraph{}
\textbf{Idea}\\
With some help I managed to develop a HYPER program (\emph{Hyp}othesis refin\emph{er}), which constructs Prolog programs through refinement of starting hypotheses. \\ This is done by searching a space of possible hypotheses and their refinements. The main idea is to take a hypothesis \emph{$H_1$} and produce a more specific hypothesis \emph{$H_2$} such that $H_2 \subset H_1$.\\
Such a set of hypotheses and their refinements is called a \emph{refinement graph}.\\Having built the graph the learning problem is reduced to searching this graph (searching from the over-general hypothesis to the most complete and consistent one).\\
An important point is that each successor of a hypothesis in the graph only covers the subset of the cases covered by the predecessor. This explains why during the search we only consider complete hypotheses, as an incomplete hypothesis cannot be refined into a complete one.
\paragraph{}
\textbf{Search}\\
We start the search with a set of start hypotheses. The refinement graph is considered to be a tree, and as the search starts with multiple start hypotheses, they become the roots of search trees. Therefore the search space we defined is just a set of trees. I have implemented best-first search by using a helper function that considers the size of a hypothesis and its accuracy with respect to an example set.
\begin{lstlisting}
Cost(H) = 10*#literals(H) + #variables(H) + 10*#negativeEgs(H)
\end{lstlisting} 
Full HYPER implementation can be found on \href{https://github.com/vitpro/ilp_alp_tal/blob/master/src/hyper.pl}{github}.

\paragraph{}
\textbf{Examples}\\
As an example I tried to implement insertion sort learning. The output produced:
\begin{lstlisting}
Hypotheses generated: 3658
Hypotheses refined:   274
To be refined:        412

sort([],[]).
sort([A|B],D) :-
  sort(B,C),
  insert_sorted(A,C,D).  
\end{lstlisting} 

\section{Abductive Logic Programming}
\emph{ALP} is a framework for ILP that is based on abductive reasoning.

\end{document}